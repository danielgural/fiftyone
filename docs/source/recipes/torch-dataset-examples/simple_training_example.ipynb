{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.utils.random as four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision import tv_tensors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as plt_patches\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacobs/miniconda3/envs/torch-dataset/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mnist_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiprocessing.set_start_method('forkserver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Training Example on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at an actual traing script with `FiftyOneTorchDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'train' already downloaded\n",
      "Split 'test' already downloaded\n",
      "Loading existing dataset 'mnist'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "mnist = foz.load_zoo_dataset(\"mnist\")\n",
    "mnist.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset:          mnist\n",
       "Media type:       image\n",
       "Num samples:      70000\n",
       "Selected samples: 0\n",
       "Selected labels:  0\n",
       "Session URL:      http://localhost:5151/"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo.launch_app(mnist, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say that for our training, we want to define some random subset of our trainset to be a validation set. We can easily do this with FiftyOne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 54000, 'test': 10000, 'validation': 6000}\n"
     ]
    }
   ],
   "source": [
    "# remove existing 'train' or 'validation' tags if they exist\n",
    "mnist.untag_samples(['train', 'validation'])\n",
    "\n",
    "# create a random split, just on the samples not tagged 'test'\n",
    "not_test = mnist.match_tags('test', bool=False)\n",
    "four.random_split(not_test, {'train' : 0.9, 'validation' : 0.1})\n",
    "print(mnist.count_sample_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset if we want it\n",
    "samples = []\n",
    "samples += mnist.match_tags('train').take(1000).values('id')\n",
    "for tag in ['test', 'validation']:\n",
    "    samples += mnist.match_tags(tag).values('id')\n",
    "\n",
    "subset = mnist.select(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacobs/fiftyone/docs/source/recipes/torch-dataset-examples/utils.py:64: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  torch.nn.init.xavier_uniform(linear_head.weight)\n",
      "Average Train Loss =   4.497025: 100%|██████████| 63/63 [00:01<00:00, 56.22it/s]\n",
      "Average Validation Loss =   1.276664: 100%|██████████| 375/375 [00:01<00:00, 215.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best lost achieved : 1.2778225633303324. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Train Loss =   1.999823: 100%|██████████| 63/63 [00:00<00:00, 121.53it/s]\n",
      "Average Validation Loss =   0.297409: 100%|██████████| 375/375 [00:01<00:00, 301.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best lost achieved : 0.2974911735057831. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Train Loss =   0.279180: 100%|██████████| 63/63 [00:00<00:00, 118.09it/s]\n",
      "Average Validation Loss =   0.955379: 100%|██████████| 375/375 [00:01<00:00, 292.05it/s]\n",
      "Average Train Loss =   0.648509: 100%|██████████| 63/63 [00:00<00:00, 112.46it/s]\n",
      "Average Validation Loss =   0.205903: 100%|██████████| 375/375 [00:01<00:00, 293.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best lost achieved : 0.20948163237112263. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Train Loss =   0.453988: 100%|██████████| 63/63 [00:00<00:00, 113.36it/s]\n",
      "Average Validation Loss =   0.364783: 100%|██████████| 375/375 [00:01<00:00, 286.46it/s]\n",
      "Average Train Loss =   0.099397: 100%|██████████| 63/63 [00:00<00:00, 134.04it/s]\n",
      "Average Validation Loss =   0.167176: 100%|██████████| 375/375 [00:01<00:00, 289.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best lost achieved : 0.17174978681871048. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Train Loss =   0.714478: 100%|██████████| 63/63 [00:00<00:00, 107.72it/s]\n",
      "Average Validation Loss =   0.514132: 100%|██████████| 375/375 [00:01<00:00, 294.92it/s]\n",
      "Average Train Loss =   0.788760: 100%|██████████| 63/63 [00:00<00:00, 114.11it/s]\n",
      "Average Validation Loss =   0.155441: 100%|██████████| 375/375 [00:01<00:00, 296.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best lost achieved : 0.15452848815266043. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Train Loss =   0.274881: 100%|██████████| 63/63 [00:00<00:00, 112.40it/s]\n",
      "Average Validation Loss =   0.131823: 100%|██████████| 375/375 [00:01<00:00, 296.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best lost achieved : 0.13296589381527155. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Train Loss =   0.020280: 100%|██████████| 63/63 [00:00<00:00, 122.89it/s]\n",
      "Average Validation Loss =   0.239573: 100%|██████████| 375/375 [00:01<00:00, 299.08it/s]\n",
      "Average Validation Loss =   0.119549: 100%|██████████| 625/625 [00:09<00:00, 68.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Results:\n",
      "Loss = 0.12128328085292596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    0 - zero       0.95      0.99      0.97       980\n",
      "     1 - one       0.99      0.99      0.99      1135\n",
      "     2 - two       0.95      0.97      0.96      1032\n",
      "   3 - three       0.97      0.95      0.96      1010\n",
      "    4 - four       0.96      0.98      0.97       982\n",
      "    5 - five       0.97      0.95      0.96       892\n",
      "     6 - six       0.99      0.95      0.97       958\n",
      "   7 - seven       0.99      0.95      0.97      1028\n",
      "   8 - eight       0.95      0.93      0.94       974\n",
      "    9 - nine       0.94      0.98      0.96      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_training.main(subset, 10, 10, 'cuda:1', '/home/jacobs/fiftyone/docs/source/recipes/torch-dataset-examples/mnist_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
